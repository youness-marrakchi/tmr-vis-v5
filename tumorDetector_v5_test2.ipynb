{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPlLEaWTUAbHoq9qR7WYWQo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youness-marrakchi/tmr-vis-v5/blob/main/tumorDetector_v5_test2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2cnNYDDerWqR",
        "outputId": "1c69f896-b486-4aa6-c05f-8472f86348c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: tensorflow-addons==0.23.0 in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons==0.23.0) (24.2)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons==0.23.0) (2.13.3)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: keras==2.15.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: kaggle in /usr/local/lib/python3.11/dist-packages (1.6.17)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (0.3.10)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.11/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from kaggle) (2.3.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.11/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kagglehub) (24.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.11/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kaggle) (3.10)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting lime\n",
            "  Using cached lime-0.2.0.1-py3-none-any.whl\n",
            "Collecting grad-cam\n",
            "  Using cached grad_cam-1.5.4-py3-none-any.whl\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.11/dist-packages (5.3.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.13.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.6.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from grad-cam) (11.1.0)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from grad-cam) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.11/dist-packages (from grad-cam) (0.20.1+cu124)\n",
            "Requirement already satisfied: ttach in /usr/local/lib/python3.11/dist-packages (from grad-cam) (0.0.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from grad-cam) (4.11.0.86)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in /usr/local/lib/python3.11/dist-packages (from nibabel) (6.5.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.11/dist-packages (from nibabel) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in /usr/local/lib/python3.11/dist-packages (from nibabel) (4.12.2)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.2.18)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.17.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.7.1->grad-cam)\n",
            "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (10.3.5.147)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.7.1->grad-cam)\n",
            "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.7.1->grad-cam) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.7.1->grad-cam) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.7.1->grad-cam) (3.0.2)\n",
            "Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cudnn-cu12 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: nvidia-cudnn-cu12, nvidia-cusolver-cu12, lime, grad-cam\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed grad-cam-1.5.4 lime-0.2.0.1 nvidia-cudnn-cu12-9.1.0.70 nvidia-cusolver-cu12-11.6.1.9\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Collecting monai\n",
            "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.11/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.11/dist-packages (from monai) (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n",
            "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: monai\n",
            "Successfully installed monai-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.15.0\n",
        "!pip install tensorflow-addons==0.23.0  # For AdamW\n",
        "!pip install keras==2.15.0\n",
        "!pip install kaggle kagglehub\n",
        "!pip install lime grad-cam nibabel\n",
        "!pip install scikit-learn plotly seaborn opencv-python matplotlib pandas\n",
        "!pip install monai  # For 3D reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import plotly.graph_objects as go\n",
        "import monai\n",
        "from monai.transforms import LoadImage, Orientation, Spacing, ResizeWithPadOrCrop\n",
        "import kagglehub\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)"
      ],
      "metadata": {
        "id": "ZAfpmKWBrL-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "class Config:\n",
        "    IMG_SIZE = (224, 224)   # Uniform input resolution\n",
        "    BATCH_SIZE = 32\n",
        "    NUM_CLASSES = 4\n",
        "\n",
        "    INITIAL_LR = 0.001\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "    EPOCHS = 10  # total target epochs (50 or more would yield better results, but i'm limited with the hardware)\n",
        "\n",
        "    DROPOUT_RATE = 0.5\n",
        "\n",
        "    PROJECT_PATH = \"/content/brain_tumor_classification\"\n",
        "    DATA_PATH = os.path.join(PROJECT_PATH, \"data\")\n",
        "    MODEL_PATH = os.path.join(PROJECT_PATH, \"models\")\n",
        "    RESULTS_PATH = os.path.join(PROJECT_PATH, \"results\")\n",
        "\n",
        "    @classmethod\n",
        "    def create_directories(cls):\n",
        "        for path in [cls.PROJECT_PATH, cls.DATA_PATH, cls.MODEL_PATH, cls.RESULTS_PATH]:\n",
        "            os.makedirs(path, exist_ok=True)"
      ],
      "metadata": {
        "id": "VU0Fo26KrQkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Download & Setup\n",
        "class DataSetup:\n",
        "    @staticmethod\n",
        "    def setup_dataset():\n",
        "        print(\"Downloading dataset using kagglehub...\")\n",
        "        kaggle_path = kagglehub.dataset_download(\"masoudnickparvar/brain-tumor-mri-dataset\")\n",
        "        kaggle_data_path = os.path.join(\"/root/.cache/kagglehub/datasets/masoudnickparvar/brain-tumor-mri-dataset/versions/1\")\n",
        "        project_data_path = Config.DATA_PATH\n",
        "\n",
        "        print(\"\\nVerifying dataset structure...\")\n",
        "        expected_dirs = ['Training', 'Testing']\n",
        "        for d in expected_dirs:\n",
        "            full_path = os.path.join(kaggle_data_path, d)\n",
        "            if not os.path.exists(full_path):\n",
        "                print(f\"ERROR: Expected directory '{d}' not found in Kaggle dataset.\")\n",
        "                return None\n",
        "\n",
        "        # Create folder structure and copy images by class\n",
        "        for split in expected_dirs:\n",
        "            split_path = os.path.join(project_data_path, split)\n",
        "            os.makedirs(split_path, exist_ok=True)\n",
        "            for class_name in ['glioma', 'meningioma', 'notumor', 'pituitary']:\n",
        "                class_path = os.path.join(split_path, class_name)\n",
        "                os.makedirs(class_path, exist_ok=True)\n",
        "                src_dir = os.path.join(kaggle_data_path, split, class_name)\n",
        "                if os.path.exists(src_dir):\n",
        "                    for file in glob.glob(os.path.join(src_dir, '*')):\n",
        "                        shutil.copy2(file, class_path)\n",
        "                else:\n",
        "                    print(f\"WARNING: Source directory {src_dir} not found.\")\n",
        "        DataSetup.verify_dataset(project_data_path)\n",
        "        return project_data_path\n",
        "\n",
        "    @staticmethod\n",
        "    def verify_dataset(data_path):\n",
        "        print(\"\\nDataset Statistics:\")\n",
        "        for split in ['Training', 'Testing']:\n",
        "            print(f\"\\n{split} Set:\")\n",
        "            total = 0\n",
        "            for class_name in ['glioma', 'meningioma', 'notumor', 'pituitary']:\n",
        "                class_path = os.path.join(data_path, split, class_name)\n",
        "                count = len(os.listdir(class_path)) if os.path.exists(class_path) else 0\n",
        "                total += count\n",
        "                print(f\"  - {class_name}: {count} images\")\n",
        "            print(f\"Total {split} images: {total}\")"
      ],
      "metadata": {
        "id": "RtOqkcQ8rgJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Pipeline using tf.data (with caching & prefetching)\n",
        "def get_rescale_layer():\n",
        "    return tf.keras.layers.Rescaling(1./255)\n",
        "\n",
        "# Use Keras built-in augmentation layers (efficient and can run on GPU)\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomRotation(0.2),\n",
        "    tf.keras.layers.RandomTranslation(0.2, 0.2),\n",
        "    tf.keras.layers.RandomZoom(0.3),\n",
        "    tf.keras.layers.RandomFlip(\"horizontal\")\n",
        "])\n",
        "\n",
        "def get_dataset(data_dir, subset=None, shuffle=True):\n",
        "    if subset in ['training', 'validation']:\n",
        "        ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "            data_dir,\n",
        "            labels=\"inferred\",\n",
        "            label_mode=\"categorical\",\n",
        "            image_size=Config.IMG_SIZE,\n",
        "            batch_size=Config.BATCH_SIZE,\n",
        "            shuffle=shuffle,\n",
        "            seed=42,\n",
        "            validation_split=0.2,\n",
        "            subset=subset\n",
        "        )\n",
        "    else:\n",
        "        ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "            data_dir,\n",
        "            labels=\"inferred\",\n",
        "            label_mode=\"categorical\",\n",
        "            image_size=Config.IMG_SIZE,\n",
        "            batch_size=Config.BATCH_SIZE,\n",
        "            shuffle=False\n",
        "        )\n",
        "    # Apply rescaling\n",
        "    rescale = get_rescale_layer()\n",
        "    ds = ds.map(lambda x, y: (rescale(x), y), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return ds.cache().prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "class DataPipeline:\n",
        "    def __init__(self, data_path):\n",
        "        training_dir = os.path.join(data_path, 'Training')\n",
        "        testing_dir  = os.path.join(data_path, 'Testing')\n",
        "        self.train_ds = get_dataset(training_dir, subset='training', shuffle=True)\n",
        "        self.val_ds   = get_dataset(training_dir, subset='validation', shuffle=False)\n",
        "        self.test_ds  = get_dataset(testing_dir, subset=None, shuffle=False)\n",
        "\n",
        "        # Augmentation for training data only\n",
        "        self.train_ds = self.train_ds.map(\n",
        "            lambda x, y: (data_augmentation(x, training=True), y),\n",
        "            num_parallel_calls=tf.data.AUTOTUNE\n",
        "        )\n"
      ],
      "metadata": {
        "id": "zuPaB2ISrzuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using ResNet50V2 as the Main Arch\n",
        "class ModelBuilder:\n",
        "    @staticmethod\n",
        "    def add_regularization(model, weight_decay=Config.WEIGHT_DECAY):\n",
        "        if not isinstance(weight_decay, float) or weight_decay <= 0.:\n",
        "            return model\n",
        "        for layer in model.layers:\n",
        "            if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.Dense):\n",
        "                layer.add_loss(lambda: tf.keras.regularizers.l2(weight_decay)(layer.kernel))\n",
        "                if hasattr(layer, 'bias') and layer.use_bias:\n",
        "                    layer.add_loss(lambda: tf.keras.regularizers.l2(weight_decay)(layer.bias))\n",
        "        return model\n",
        "\n",
        "    @staticmethod\n",
        "    def build_model(architecture, input_shape=(224, 224, 3), num_classes=Config.NUM_CLASSES):\n",
        "        if architecture == 'resnet':\n",
        "            base_model = tf.keras.applications.ResNet50V2(\n",
        "                weights='imagenet', include_top=False, input_shape=input_shape\n",
        "            )\n",
        "        elif architecture == 'mobilenet':\n",
        "            base_model = tf.keras.applications.MobileNetV3Large(\n",
        "                weights='imagenet', include_top=False, input_shape=input_shape\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported architecture. Choose 'resnet' or 'mobilenet'.\")\n",
        "        x = base_model.output\n",
        "        x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        x = tf.keras.layers.LayerNormalization()(x)\n",
        "        x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
        "        x = tf.keras.layers.Dropout(Config.DROPOUT_RATE)(x)\n",
        "        x = tf.keras.layers.LayerNormalization()(x)\n",
        "        predictions = tf.keras.layers.Dense(Config.NUM_CLASSES, activation='softmax')(x)\n",
        "        model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
        "        return ModelBuilder.add_regularization(model)\n",
        "\n",
        "# Training Manager (with incremental training)\n",
        "class TrainingManager:\n",
        "    def __init__(self, model, train_ds, val_ds, test_ds):\n",
        "        self.model = model\n",
        "        self.train_ds = train_ds\n",
        "        self.val_ds = val_ds\n",
        "        self.test_ds = test_ds\n",
        "\n",
        "    def compile_model(self):\n",
        "        optimizer = tfa.optimizers.AdamW(\n",
        "            learning_rate=Config.INITIAL_LR,\n",
        "            weight_decay=Config.WEIGHT_DECAY\n",
        "        )\n",
        "        self.model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss='categorical_crossentropy',\n",
        "            metrics=[\n",
        "                'accuracy',\n",
        "                tf.keras.metrics.Precision(),\n",
        "                tf.keras.metrics.Recall(),\n",
        "                tf.keras.metrics.AUC()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    def get_callbacks(self, model_name):\n",
        "        return [\n",
        "            tf.keras.callbacks.ModelCheckpoint(\n",
        "                os.path.join(Config.MODEL_PATH, f'best_{model_name}.h5'),\n",
        "                monitor='val_accuracy',\n",
        "                save_best_only=True,\n",
        "                mode='max'\n",
        "            ),\n",
        "            tf.keras.callbacks.ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=3,\n",
        "                min_lr=1e-6,\n",
        "                verbose=1\n",
        "            ),\n",
        "            tf.keras.callbacks.EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=10,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    def train_incrementally(self, model_name, total_epochs=10, increment=2):\n",
        "        # If training is resumed, the model should already be compiled.\n",
        "        current_epoch = 0\n",
        "        checkpoint_path = os.path.join(Config.MODEL_PATH, f'{model_name}_checkpoint.h5')\n",
        "        while current_epoch < total_epochs:\n",
        "            print(f\"Training from epoch {current_epoch} to {current_epoch + increment}...\")\n",
        "            history = self.model.fit(\n",
        "                self.train_ds,\n",
        "                validation_data=self.val_ds,\n",
        "                epochs=current_epoch + increment,\n",
        "                initial_epoch=current_epoch,\n",
        "                callbacks=self.get_callbacks(model_name)\n",
        "            )\n",
        "            current_epoch += increment\n",
        "            # saving the model (including optimizer state) to resume later if needed\n",
        "            self.model.save(checkpoint_path)\n",
        "            print(f\"Checkpoint saved at epoch {current_epoch}\")\n",
        "        return history"
      ],
      "metadata": {
        "id": "XPwXDwmItgmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization Manager (for plotting training history)\n",
        "class VisualizationManager:\n",
        "    def __init__(self):\n",
        "        self.results_path = Config.RESULTS_PATH\n",
        "\n",
        "    def save_plot(self, fig, filename):\n",
        "        plt.savefig(os.path.join(self.results_path, filename))\n",
        "        plt.close()\n",
        "\n",
        "    def plot_training_history(self, history, model_name):\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "        ax1.plot(history.history['accuracy'], marker='o')\n",
        "        ax1.plot(history.history['val_accuracy'], marker='o')\n",
        "        ax1.set_title(f'{model_name} - Accuracy')\n",
        "        ax1.set_xlabel('Epoch')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.legend(['Train', 'Validation'])\n",
        "        ax2.plot(history.history['loss'], marker='o')\n",
        "        ax2.plot(history.history['val_loss'], marker='o')\n",
        "        ax2.set_title(f'{model_name} - Loss')\n",
        "        ax2.set_xlabel('Epoch')\n",
        "        ax2.set_ylabel('Loss')\n",
        "        ax2.legend(['Train', 'Validation'])\n",
        "        plt.tight_layout()\n",
        "        self.save_plot(fig, f'{model_name}_training_history.png')\n"
      ],
      "metadata": {
        "id": "cxS7nzxItlIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing Function (Upload an image and predict its class)\n",
        "def test_model(model):\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        print(\"Processing image:\", filename)\n",
        "        img = tf.keras.preprocessing.image.load_img(filename, target_size=Config.IMG_SIZE)\n",
        "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = img_array / 255.0  # apply rescaling\n",
        "        predictions = model.predict(img_array)\n",
        "        predicted_class = np.argmax(predictions, axis=1)\n",
        "        class_names = sorted([\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"])\n",
        "        print(\"Predicted class index:\", predicted_class[0])\n",
        "        print(\"Predicted class name:\", class_names[predicted_class[0]])\n"
      ],
      "metadata": {
        "id": "ZJYa9RE9sQxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# Main Execution\n",
        "# ======================================================\n",
        "def main():\n",
        "    # Create directories\n",
        "    Config.create_directories()\n",
        "\n",
        "    # Download and prepare dataset\n",
        "    data_path = DataSetup.setup_dataset()\n",
        "    if not data_path:\n",
        "        return\n",
        "\n",
        "    # Build tf.data pipelines\n",
        "    data_pipeline = DataPipeline(data_path)\n",
        "    train_ds, val_ds, test_ds = data_pipeline.train_ds, data_pipeline.val_ds, data_pipeline.test_ds\n",
        "\n",
        "    # Build model\n",
        "    model_name = 'resnet'\n",
        "    checkpoint_path = os.path.join(Config.MODEL_PATH, f'{model_name}_checkpoint.h5')\n",
        "    if os.path.exists(checkpoint_path):\n",
        "        model = tf.keras.models.load_model(checkpoint_path, compile=False)\n",
        "        print(\"Loaded checkpoint from\", checkpoint_path)\n",
        "        # Recompile model after loading\n",
        "        optimizer = tfa.optimizers.AdamW(learning_rate=Config.INITIAL_LR, weight_decay=Config.WEIGHT_DECAY)\n",
        "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    else:\n",
        "        model = ModelBuilder.build_model(model_name)\n",
        "        optimizer = tfa.optimizers.AdamW(learning_rate=Config.INITIAL_LR, weight_decay=Config.WEIGHT_DECAY)\n",
        "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "        print(\"Created new model.\")\n",
        "\n",
        "    # Initialize Training Manager and train incrementally (2 or 1 epochs at a time until 10 epochs are reached)\n",
        "    # going with such small epochs because of my potato laptop\n",
        "    trainer = TrainingManager(model, train_ds, val_ds, test_ds)\n",
        "    trainer.compile_model()  # Ensure model is compiled\n",
        "    history = trainer.train_incrementally(model_name, total_epochs=Config.EPOCHS, increment=1)\n",
        "\n",
        "    # Evaluate model on test set\n",
        "    test_loss, test_acc = model.evaluate(test_ds)\n",
        "    print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "    # Plot training history\n",
        "    vis_manager = VisualizationManager()\n",
        "    vis_manager.plot_training_history(history, model_name)\n",
        "\n",
        "    # Allow user to upload a scan and test the model\n",
        "    print(\"Upload an image to test the model:\")\n",
        "    test_model(model)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "UKwBV0Q_tvPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}